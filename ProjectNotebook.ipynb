{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9f054e-5ca2-440b-a0d0-dd16cd583f92",
   "metadata": {},
   "source": [
    "## Exploring Philosophical Texts Across Gender, Region, and Time with Text Analytics\n",
    "### Haley Egan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18b654-c19f-42b5-807a-3431ce39bcd1",
   "metadata": {},
   "source": [
    "#### Project Overview\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369595c6-41e1-448a-9691-937d2e0c9084",
   "metadata": {},
   "source": [
    "The goal of this project is to explore the cultural patterns in philosophical texts. Main topics and cultural themes are analyzed across the texts as a whole. Topics and themes are also examined between groups, such as between male and female philosochical writers, between regions/nations, and across time. Text Analytics is a powerful tool to help us understand and extract cultural patterns from large quantities of texts.  \n",
    "\n",
    "Key Questions: \n",
    "- Do male and female philosophers explore different topics, or share similarites? \n",
    "- Are different topics discussed in different regions of the world? \n",
    "- Are different topics discussed in different time periods? \n",
    "- Can the key concepts of philosophical texts be extracted from each text, in an interpretable way? \n",
    "- What are the most important issues that philosophers are concerned with? Do these change over time, and do they differ based on gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f5fbc2-114c-4d6f-ac57-b04b4fc2e037",
   "metadata": {},
   "source": [
    "#### Project Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccc1df-dfdc-42ca-85dc-a99c8c0a642b",
   "metadata": {},
   "source": [
    "For this project, 21 philosophical texts were collected. Ten texts are by male Western philosophers, and span from 4th century BC to the 19th century AD. Four philosophical texts are by men from other parts of the world, including Asia and South America. Seven texts were collected by female Western philosophers, most of which are from the 20th century. These texts were collected from Project Gutenberg, and other online document archives. The texts are all in Plain-Text format, for easier use in data cleaning, parsing, and manipulation. Due to the necessity of the plain-text format, the available texts were limited, especially for the female philosophers. Most (known) published female philosophers are from the modern era, with limited free access to their works in plain-text form. This is the same for modern male philosophers. The distribution of texts is not even across time/gender, which must be taken into account when analysing the texts. There are many philosophical texts in the world, and this sample barely scratches the surface. Further exploration with more texts would provide greater understandings, and should be considered for future studies. However, there should still be enough textual data in order to address many cultural questions when looking at philosophical texts.\n",
    "\n",
    "- 10 Western Philosophical Texts by Male Authors: \n",
    "    - Aristotle: Nicomachean Ethics (4th century BC)\n",
    "    - Plato: The Republic (4th century BC)\n",
    "    - Cicero: On Moral Duties / De Officiis (44 BC)\n",
    "    - David Hume: An Enquiry Concerning Human Understanding (1748)\n",
    "    - Immanuel Kant: Fundamental Principles of the Metaphysic of Morals (1785)\n",
    "    - Karl Marx: The Communist Manifesto (1848)\n",
    "    - John Stuart Mill: Utilitarianism (1861) \n",
    "    - Friedrich Nietzsche: Beyond Good and Evil (1886)\n",
    "    - Søren Kierkegaard: Selections from the Writings of Kierkegaard (1923)\n",
    "    - Michel Foucault: The Order of Things (1966)\n",
    "- 4 Non-Western Philosophical Texts by Male Authors: \n",
    "    - Laozi (Lao Tzu): Tao Te Ching (400 BC) \n",
    "    - Paulo Freire: Pedagogy of the Oppressed (1968) \n",
    "    - **Sun Tzu: The Art of War (5th century BC)**\n",
    "    - Herman Hesse: Siddartha (1922) \n",
    "- 7 Western Phiosophical Texts by Female Authors:\n",
    "    - Mary Wollstonecraft: A Vindication of the Rights of Men (1790)\n",
    "    - Mary Wollstonecraft: A Vindication of the Rights of Woman (1792)\n",
    "    - Harriet Taylor Mill: The Enfranchisement of Women (1852)\n",
    "    - Simone de Beauvoir: The Second Sex (1952)\n",
    "    - Hannah Arendt: The Origins of Totalitarianism (1951)\n",
    "    - bell hooks: Ain’t I a Woman: Black Women and Feminism (1981)\n",
    "    - bell hooks: Feminist Class Struggle (2002) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfaeef-6f60-48c5-a3aa-4597d8d6892a",
   "metadata": {},
   "source": [
    "#### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb9b368-f976-4f5c-8032-89bda569d88e",
   "metadata": {},
   "source": [
    "Several Text Analytics tools are used for this project.\n",
    "- Bag-of-words:\n",
    "- TF-IDF:\n",
    "- Principle Component Analysis (PCA): \n",
    "- Latent Diriclet Analysis (LDA):\n",
    "- Topic Modeling:\n",
    "- Word Embeddings: word2vec\n",
    "- Visualizations:\n",
    "    - Cluster Diagrams:\n",
    "    - t-SNE:\n",
    "    - Dispersion Plots:\n",
    "    - Correlation heatmaps:\n",
    "    \n",
    "**Step 1**: Clean texts - import texts, remove beginning and end of texts that are not part of the main corpus. \n",
    "\n",
    "**Step 2**: Combine texts into one dataframe. From combined dataframe, create library table (LIB), document table (DOC), token table (TOKEN), and vocabulary table (VOCAB), all exported as csv files. \n",
    "- LIB: basic metadata about each book\n",
    "- DOC: preserved paragraphs of each book and appropriate OHCO index\n",
    "- TOKEN: OHCO index and parts-of-speech tags derived from NLTK\n",
    "- VOCAB: NLTK to extract stopwords, porter stems, 'pos_max' that contains most frequent parts-of-speech tags from TOKEN table\n",
    "** These documents do not follow a traditional chapter structure\n",
    "\n",
    "**Step 3**:\n",
    "\n",
    "**Step 4**: \n",
    "\n",
    "**Step 5**:\n",
    "\n",
    "**Step 6**:\n",
    "\n",
    "**Step 7**:\n",
    "\n",
    "**Step 8**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "61a85e2e-5558-40dc-baa3-f1decac15fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e3ea1048-365d-42f2-8f1b-7d8305b2b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d0f80175-e4bc-4bc5-8134-c7530a57a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\haley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\haley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\haley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\haley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLTK downloads\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba68ed-fe35-4b88-9567-1bcac399e85f",
   "metadata": {},
   "source": [
    "#### OHCO Model & Structure Decisions\n",
    "\n",
    "An OHCO Model stands for Ordered Hierarchy of Content Objects. Breaking text elements down to the OHCO hierarchical levels allows us to create a database of text elements for data exploration. \n",
    "\n",
    "For this project, the OHCO is set to text_id, which is the unique ID given to each text to help distinguish it quickly from other texts, para_num, which is the unique count index given to each paragraph per text, sent_num, the unique count index given to each sentence per text, and token_num, the unique count index given for each individual token, or word. Many OHCO models include chapter numbers, so that the texts can be examined on a chapter level. This is often less computationally costly than examining a text at the paragraph or sentence level, especially for very long texts. However, for this project chapters are not included, because most of the philosophical texts do not follow a chapter structure. For example, the two texts by Wollstonecraft follow a letter format, and the texts by hooks are in essay format. Due to the inconsistencies in document structure, the documents are broken down to the paragraph, sentence, and token level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a126be0e-16e7-401b-a196-2c971c6cd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set OHCO\n",
    "OHCO = ['text_id', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c5b55e52-ba60-41bd-9556-aa642a4083dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory for philosophy texts\n",
    "philostext_dir = 'philostexts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "26f63854-c86c-4f88-92b6-f1b693bcca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify start and end of texts, make uniform chapters\n",
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "chap_pats = {\n",
    "    1: {\n",
    "        'start_line': 17,\n",
    "        'end_line': 7723},\n",
    "    2: {\n",
    "        'start_line': 14,\n",
    "        'end_line': 9370},\n",
    "    3: {\n",
    "        'start_line': 7,\n",
    "        'end_line': 180},\n",
    "     4: {\n",
    "        'start_line': 90,\n",
    "        'end_line': 12102}, \n",
    "      5: {\n",
    "        'start_line': 1081,\n",
    "        'end_line': 19707},\n",
    "      6: {\n",
    "        'start_line': 396,\n",
    "        'end_line': 4716},\n",
    "      7: {\n",
    "        'start_line': 502,\n",
    "        'end_line': 30458},\n",
    "      8: {\n",
    "        'start_line': 155,\n",
    "        'end_line': 1371},\n",
    "      9: {\n",
    "        'start_line': 72,\n",
    "        'end_line': 3992},\n",
    "      10: {\n",
    "        'start_line': 89,\n",
    "        'end_line': 5281},\n",
    "    11: {\n",
    "        'start_line': 62,\n",
    "        'end_line': 3113},\n",
    "    12: {\n",
    "        'start_line': 107,\n",
    "        'end_line': 8653},\n",
    "    13: {\n",
    "        'start_line': 80,\n",
    "        'end_line': 1433},\n",
    "    14: {\n",
    "        'start_line': 75,\n",
    "        'end_line': 2319},\n",
    "    15: {\n",
    "        'start_line': 618,\n",
    "        'end_line': 9483},\n",
    "    16: {\n",
    "        'start_line': 151,\n",
    "        'end_line': 6007},\n",
    "    17: {\n",
    "        'start_line': 61,\n",
    "        'end_line': 24563},\n",
    "    18: {\n",
    "        'start_line': 902,\n",
    "        'end_line': 39254},\n",
    "    19: {\n",
    "        'start_line': 12,\n",
    "        'end_line': 2437},\n",
    "    #20: {\n",
    "     #   'start_line': 268,\n",
    "     #   'end_line': 6783,\n",
    "    # },\n",
    "    21: {\n",
    "        'start_line': 135,\n",
    "        'end_line': 2739}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "927ecd58-df09-46c5-be29-6d04291f2423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['philostexts\\\\Aristotle_NicomachaenEthics-1.txt',\n",
       " 'philostexts\\\\Cicero_OnDuties-4.txt',\n",
       " 'philostexts\\\\Foucault_TheOrderofThings-5.txt',\n",
       " 'philostexts\\\\Freire_PedagogyOfTheOppressed-6.txt',\n",
       " 'philostexts\\\\HannahArendt_TheOriginsofTotalitarianism-7.txt',\n",
       " 'philostexts\\\\HarrietTaylorMill_EnfranchisementofWomen-8.txt',\n",
       " 'philostexts\\\\Hesse_Siddhartha-9.txt',\n",
       " 'philostexts\\\\Hume_AnEnquiryConcerningHumanUnderstanding-10.txt',\n",
       " 'philostexts\\\\Kant_MetaphysicsOfMorals-11.txt',\n",
       " 'philostexts\\\\Kierkegaard_CollectionOfWritings-12.txt',\n",
       " 'philostexts\\\\Laozi_TaoTeChing-21.txt',\n",
       " 'philostexts\\\\Marx_CommunistManifesto-13.txt',\n",
       " 'philostexts\\\\MaryWollstonecraft_AVindicationOfTheRightsofMen-14.txt',\n",
       " 'philostexts\\\\MaryWollstonecraft_AVindicationOfTheRightsofWoman-15.txt',\n",
       " 'philostexts\\\\Nietzsche_BeyondGoodandEvil-16.txt',\n",
       " 'philostexts\\\\Plato_TheRepublic-17.txt',\n",
       " 'philostexts\\\\Simonedebeauvoir_TheSecondSex-18.txt',\n",
       " 'philostexts\\\\StuartMill_Utilitarianism-19.txt',\n",
       " 'philostexts\\\\bellhooks_AintIAWoman-2.txt',\n",
       " 'philostexts\\\\bellhooks_FeministClassStruggle-3.txt']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a list of all text files\n",
    "text_list = [text for text in sorted(glob(philostext_dir+'/*.txt'))]\n",
    "text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5d8af-c69b-49f1-99b8-78ebb91d202e",
   "metadata": {},
   "source": [
    "### Clean Texts and Build Library and Document Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5f16cf3f-d11c-4463-9991-cebd2e5ec8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean texts, split into paragraphs, and build dataframes\n",
    "def clean_texts(text_list, chap_pats, OHCO=OHCO):\n",
    "    lib = []\n",
    "    doc = []\n",
    "    for text in text_list:\n",
    "        # Get ID from filename\n",
    "        text_id = int(text.split('-')[-1].split('.')[0])\n",
    "        #print(text_id)\n",
    "\n",
    "        #get text title \n",
    "        text_title = text.split('_')[-1].split('-')[0]\n",
    "        #print(text_title)\n",
    "\n",
    "        #get text author\n",
    "        text_author = text.split('\\\\')[-1].split('_')[0]\n",
    "        #print(text_author)    \n",
    "\n",
    "        #read files as lines\n",
    "        lines = open(text, 'r', encoding='utf-8-sig').readlines()\n",
    "        \n",
    "        #create dataframe to store text details\n",
    "        df = pd.DataFrame(lines, columns=['line_str']) #add lines to df\n",
    "        df.index.name = 'line_num' #set line_num as index for each line_str\n",
    "        df.line_str = df.line_str.str.strip() #strip white space from lines\n",
    "        #df['text_id'] = text_id #add text_id column to df\n",
    "        \n",
    "        #remove inconsistent chapter headings\n",
    "        df.line_str = df.line_str.replace(r'CHAPTER', '').str.strip()\n",
    "        df.line_str = df.line_str.replace(r'Chapter', '').str.strip()\n",
    "        \n",
    "        #remove page numbers\n",
    "        df.line_str = df.line_str.str.replace(r'[0-9]+', '')\n",
    "        \n",
    "        # fix characters to improve tokenization\n",
    "        df.line_str = df.line_str.str.replace('—', ' — ')\n",
    "        df.line_str = df.line_str.str.replace('-', ' - ')\n",
    "        \n",
    "        #remove unimportant stuff at begininng and end of texts\n",
    "        a = chap_pats[text_id]['start_line'] - 1\n",
    "        b = chap_pats[text_id]['end_line'] + 1\n",
    "        df = df.iloc[a:b]    \n",
    "\n",
    "        #split into paragraphs\n",
    "        df = df['line_str'].str.split(r'\\n\\n+', expand=True).stack().to_frame().rename(columns={0:'para_str'})\n",
    "        df.index.names = OHCO[1:3]\n",
    "        df['para_str'] = df['para_str'].str.replace(r'\\n', ' ').str.strip()\n",
    "        df = df[~df['para_str'].str.match(r'^\\s*$')] # Remove empty paragraphs    \n",
    "\n",
    "        # Set index\n",
    "        df['text_id'] = text_id\n",
    "        df = df.reset_index().set_index(OHCO[:2])  \n",
    "        df = df.drop(['sent_num'], axis=1) #drop sent_num - not needed at this point  \n",
    "\n",
    "        #append extracted into to lists\n",
    "        lib.append((text_id, text_title, text_author, text))\n",
    "        doc.append(df)\n",
    "    \n",
    "    docs = pd.concat(doc) #put all doc into into dataframe format \n",
    "    #create new df with title, author, file, and text id index\n",
    "    library = pd.DataFrame(lib, columns=['text_id', 'text_title', 'text_author', 'text_file']).set_index('text_id')\n",
    "    return docs, library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d54fedda-6ae1-4342-acd1-12d630f6e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to make LIB and DOC tables\n",
    "DOC, LIB = clean_texts(text_list, chap_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e637cd53-b902-4afa-bf19-a105e86b066a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_title</th>\n",
       "      <th>text_author</th>\n",
       "      <th>text_file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Siddhartha</td>\n",
       "      <td>Hesse</td>\n",
       "      <td>philostexts\\Hesse_Siddhartha-9.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PedagogyOfTheOppressed</td>\n",
       "      <td>Freire</td>\n",
       "      <td>philostexts\\Freire_PedagogyOfTheOppressed-6.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MetaphysicsOfMorals</td>\n",
       "      <td>Kant</td>\n",
       "      <td>philostexts\\Kant_MetaphysicsOfMorals-11.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BeyondGoodandEvil</td>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>philostexts\\Nietzsche_BeyondGoodandEvil-16.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AVindicationOfTheRightsofWoman</td>\n",
       "      <td>MaryWollstonecraft</td>\n",
       "      <td>philostexts\\MaryWollstonecraft_AVindicationOfT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FeministClassStruggle</td>\n",
       "      <td>bellhooks</td>\n",
       "      <td>philostexts\\bellhooks_FeministClassStruggle-3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TaoTeChing</td>\n",
       "      <td>Laozi</td>\n",
       "      <td>philostexts\\Laozi_TaoTeChing-21.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TheOrderofThings</td>\n",
       "      <td>Foucault</td>\n",
       "      <td>philostexts\\Foucault_TheOrderofThings-5.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Utilitarianism</td>\n",
       "      <td>StuartMill</td>\n",
       "      <td>philostexts\\StuartMill_Utilitarianism-19.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OnDuties</td>\n",
       "      <td>Cicero</td>\n",
       "      <td>philostexts\\Cicero_OnDuties-4.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text_title         text_author  \\\n",
       "text_id                                                       \n",
       "9                            Siddhartha               Hesse   \n",
       "6                PedagogyOfTheOppressed              Freire   \n",
       "11                  MetaphysicsOfMorals                Kant   \n",
       "16                    BeyondGoodandEvil           Nietzsche   \n",
       "15       AVindicationOfTheRightsofWoman  MaryWollstonecraft   \n",
       "3                 FeministClassStruggle           bellhooks   \n",
       "21                           TaoTeChing               Laozi   \n",
       "5                      TheOrderofThings            Foucault   \n",
       "19                       Utilitarianism          StuartMill   \n",
       "4                              OnDuties              Cicero   \n",
       "\n",
       "                                                 text_file  \n",
       "text_id                                                     \n",
       "9                       philostexts\\Hesse_Siddhartha-9.txt  \n",
       "6          philostexts\\Freire_PedagogyOfTheOppressed-6.txt  \n",
       "11             philostexts\\Kant_MetaphysicsOfMorals-11.txt  \n",
       "16          philostexts\\Nietzsche_BeyondGoodandEvil-16.txt  \n",
       "15       philostexts\\MaryWollstonecraft_AVindicationOfT...  \n",
       "3        philostexts\\bellhooks_FeministClassStruggle-3.txt  \n",
       "21                     philostexts\\Laozi_TaoTeChing-21.txt  \n",
       "5              philostexts\\Foucault_TheOrderofThings-5.txt  \n",
       "19            philostexts\\StuartMill_Utilitarianism-19.txt  \n",
       "4                        philostexts\\Cicero_OnDuties-4.txt  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "967a17cc-d7d4-486b-867d-0817770dadcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>para_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>18616</th>\n",
       "      <td>In her book The Adolescent Girl, Mme Evard als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>7633</th>\n",
       "      <td>ideas in the idea of good, though he does not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>20526</th>\n",
       "      <td>and now that she is grasped, she is swept away...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>2242</th>\n",
       "      <td>conception of justice, as to maintain that all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>19267</th>\n",
       "      <td>invites or excites intelligence.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>17777</th>\n",
       "      <td>tion of wealth) that proceed by relating disco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11604</th>\n",
       "      <td>all beings emerge into their precarious, glitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>5939</th>\n",
       "      <td>bruised, but full of hopes which as yet lack n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>8496</th>\n",
       "      <td>without reading him, in the same fashion in wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>29323</th>\n",
       "      <td>ness that has come out of Soviet Russia since ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           para_str\n",
       "text_id para_num                                                   \n",
       "18      18616     In her book The Adolescent Girl, Mme Evard als...\n",
       "17      7633      ideas in the idea of good, though he does not ...\n",
       "18      20526     and now that she is grasped, she is swept away...\n",
       "19      2242      conception of justice, as to maintain that all...\n",
       "17      19267                      invites or excites intelligence.\n",
       "5       17777     tion of wealth) that proceed by relating disco...\n",
       "        11604     all beings emerge into their precarious, glitt...\n",
       "16      5939      bruised, but full of hopes which as yet lack n...\n",
       "17      8496      without reading him, in the same fashion in wh...\n",
       "7       29323     ness that has come out of Soviet Russia since ..."
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a394ef1-75d7-411b-973a-28d198774512",
   "metadata": {},
   "source": [
    "### Create TOKEN table to extract NLTK Part-of-Speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8dce7354-4d36-492e-b27d-e86bf9991f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "    # Paragraphs to Sentences\n",
    "    df = doc_df.para_str\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    # Sentences to Tokens\n",
    "    # Local function to pick tokenizer\n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x)))\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0fed85c4-7693-4f7d-a4e3-7e6548dfb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = tokenize(DOC, ws=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "6ec0dead-e223-46f6-91d9-4a56263885d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">16</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Every, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>Every</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(art, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(and, CC)</td>\n",
       "      <td>CC</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(every, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>every</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(inquiry,, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>inquiry,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          pos_tuple pos token_str\n",
       "text_id para_num sent_num token_num                              \n",
       "1       16       0        0             (Every, DT)  DT     Every\n",
       "                          1               (art, NN)  NN       art\n",
       "                          2               (and, CC)  CC       and\n",
       "                          3             (every, DT)  DT     every\n",
       "                          4          (inquiry,, NN)  NN  inquiry,"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e11c6-eb17-44bd-a27a-9aac334020dc",
   "metadata": {},
   "source": [
    "### Create VOCAB Table with NLTK Stopwords, Porter Stems, Most Frequent Parts-of-Speech Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "315b22ee-bf66-42ee-8628-3843961782ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>26650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52120</th>\n",
       "      <td>ἅπαν</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52121</th>\n",
       "      <td>ἐξοίχεται</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52122</th>\n",
       "      <td>ὁρμαί</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52123</th>\n",
       "      <td>ὁρμάς</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52124</th>\n",
       "      <td>ὁρμή</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52125 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          term_str      n  num\n",
       "term_id                       \n",
       "0                   26650    0\n",
       "1                0     28    1\n",
       "2               00     13    1\n",
       "3               01      6    1\n",
       "4              011      1    1\n",
       "...            ...    ...  ...\n",
       "52120         ἅπαν      1    0\n",
       "52121    ἐξοίχεται      1    0\n",
       "52122        ὁρμαί      1    0\n",
       "52123        ὁρμάς      1    0\n",
       "52124         ὁρμή      2    0\n",
       "\n",
       "[52125 rows x 3 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract a vocabulary from the TOKEN table\n",
    "TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '') #lowercase all, remove anything that's not a letter\n",
    "\n",
    "VOCAB = TOKEN.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'\n",
    "\n",
    "VOCAB['num'] = VOCAB.term_str.str.match(\"\\d+\").astype('int')\n",
    "\n",
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9f0bc7d6-ddfa-4d49-8f5e-c5bf5293c849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>theirs</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haven</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>these</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shouldn</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dummy\n",
       "term_str       \n",
       "theirs        1\n",
       "at            1\n",
       "are           1\n",
       "m             1\n",
       "haven         1\n",
       "these         1\n",
       "his           1\n",
       "shouldn       1\n",
       "t             1\n",
       "ll            1"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add stopwords\n",
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1\n",
    "sw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9dfacee6-608f-43e1-9f09-6644ecca7776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28755</th>\n",
       "      <td>ma</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45399</th>\n",
       "      <td>such</td>\n",
       "      <td>2647</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>an</td>\n",
       "      <td>6779</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33823</th>\n",
       "      <td>own</td>\n",
       "      <td>2324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46823</th>\n",
       "      <td>their</td>\n",
       "      <td>8838</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>a</td>\n",
       "      <td>34574</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51950</th>\n",
       "      <td>your</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30964</th>\n",
       "      <td>most</td>\n",
       "      <td>2463</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23051</th>\n",
       "      <td>how</td>\n",
       "      <td>1660</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>at</td>\n",
       "      <td>5732</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str      n  num  stop\n",
       "term_id                           \n",
       "28755         ma     12    0     1\n",
       "45399       such   2647    0     1\n",
       "3329          an   6779    0     1\n",
       "33823        own   2324    0     1\n",
       "46823      their   8838    0     1\n",
       "1418           a  34574    0     1\n",
       "51950       your    917    0     1\n",
       "30964       most   2463    0     1\n",
       "23051        how   1660    0     1\n",
       "4711          at   5732    0     1"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB['stop'] = VOCAB.term_str.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')\n",
    "\n",
    "VOCAB[VOCAB.stop == 1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2ee8734b-bc17-4524-9f93-42b58f9d749d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>p_stem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10433</th>\n",
       "      <td>considerando</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>considerando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>coeperat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>coeperat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40772</th>\n",
       "      <td>rivals</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34730</th>\n",
       "      <td>pensioners</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34892</th>\n",
       "      <td>periculosum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>periculosum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36588</th>\n",
       "      <td>praedixisse</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>praedixiss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42844</th>\n",
       "      <td>showiness</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>showi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51326</th>\n",
       "      <td>whichever</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>whichev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29813</th>\n",
       "      <td>memoriam</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>memoriam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45728</th>\n",
       "      <td>supposer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>suppos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term_str   n  num  stop        p_stem\n",
       "term_id                                           \n",
       "10433    considerando   1    0     0  considerando\n",
       "9171         coeperat   1    0     0      coeperat\n",
       "40772          rivals  18    0     0         rival\n",
       "34730      pensioners   1    0     0       pension\n",
       "34892     periculosum   1    0     0   periculosum\n",
       "36588     praedixisse   1    0     0    praedixiss\n",
       "42844       showiness   1    0     0         showi\n",
       "51326       whichever   5    0     0       whichev\n",
       "29813        memoriam   5    0     0      memoriam\n",
       "45728        supposer   1    0     0        suppos"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add stems\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "VOCAB['p_stem'] = VOCAB.term_str.apply(stemmer.stem)\n",
    "\n",
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "97028255-a343-421b-b9bf-132e032407d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>17580</th>\n",
       "      <th>0</th>\n",
       "      <th>8</th>\n",
       "      <td>(and, CC)</td>\n",
       "      <td>CC</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>24964</th>\n",
       "      <th>0</th>\n",
       "      <th>11</th>\n",
       "      <td>(war, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>war</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>6702</th>\n",
       "      <th>0</th>\n",
       "      <th>9</th>\n",
       "      <td>(by, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>3073</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>(of, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">18</th>\n",
       "      <th>36927</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <td>(lives., NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>lives.</td>\n",
       "      <td>lives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18234</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <td>(her, PRP$)</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>her</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1788</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <td>(slaveholding, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>slaveholding</td>\n",
       "      <td>slaveholding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>4392</th>\n",
       "      <th>0</th>\n",
       "      <th>10</th>\n",
       "      <td>(between, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>between</td>\n",
       "      <td>between</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>38988</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>(She, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>She</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2481</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pos_tuple   pos     token_str  \\\n",
       "text_id para_num sent_num token_num                                           \n",
       "5       17580    0        8                   (and, CC)    CC           and   \n",
       "7       24964    0        11                  (war, NN)    NN           war   \n",
       "2       6702     0        9                    (by, IN)    IN            by   \n",
       "15      3073     0        1                    (of, IN)    IN            of   \n",
       "18      36927    0        4                (lives., NN)    NN        lives.   \n",
       "        18234    0        2                 (her, PRP$)  PRP$           her   \n",
       "2       1788     1        2          (slaveholding, NN)    NN  slaveholding   \n",
       "16      4392     0        10              (between, IN)    IN       between   \n",
       "18      38988    1        0                  (She, PRP)   PRP           She   \n",
       "1       2481     0        6                   (the, DT)    DT           the   \n",
       "\n",
       "                                         term_str  \n",
       "text_id para_num sent_num token_num                \n",
       "5       17580    0        8                   and  \n",
       "7       24964    0        11                  war  \n",
       "2       6702     0        9                    by  \n",
       "15      3073     0        1                    of  \n",
       "18      36927    0        4                 lives  \n",
       "        18234    0        2                   her  \n",
       "2       1788     1        2          slaveholding  \n",
       "16      4392     0        10              between  \n",
       "18      38988    1        0                   she  \n",
       "1       2481     0        6                   the  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d86b25df-c0cb-4d1b-b649-bfbe7db6484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 'term_id' column to table to make it easier of merging tables \n",
    "TOKEN['term_id'] = TOKEN.term_str.map(VOCAB.reset_index().set_index('term_str').term_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3a2dddee-ec0e-4eb1-a1d0-cbc6a1f4563b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>term_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">16</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Every, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>Every</td>\n",
       "      <td>every</td>\n",
       "      <td>17469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(art, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>art</td>\n",
       "      <td>art</td>\n",
       "      <td>4390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(and, CC)</td>\n",
       "      <td>CC</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>3416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(every, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>every</td>\n",
       "      <td>every</td>\n",
       "      <td>17469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(inquiry,, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>inquiry,</td>\n",
       "      <td>inquiry</td>\n",
       "      <td>25045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          pos_tuple pos token_str term_str  \\\n",
       "text_id para_num sent_num token_num                                          \n",
       "1       16       0        0             (Every, DT)  DT     Every    every   \n",
       "                          1               (art, NN)  NN       art      art   \n",
       "                          2               (and, CC)  CC       and      and   \n",
       "                          3             (every, DT)  DT     every    every   \n",
       "                          4          (inquiry,, NN)  NN  inquiry,  inquiry   \n",
       "\n",
       "                                     term_id  \n",
       "text_id para_num sent_num token_num           \n",
       "1       16       0        0            17469  \n",
       "                          1             4390  \n",
       "                          2             3416  \n",
       "                          3            17469  \n",
       "                          4            25045  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f06f171f-a734-4d51-97fc-df66eaa12da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, add a feature named \"pos_max\" to the VOCAB table that contains the most frequently \n",
    "#associated part-of-speech tag, as found in the TOKEN table, with each term.\n",
    "VOCAB['pos_max'] = TOKEN.groupby(['term_id', 'pos']).count().iloc[:,0].unstack().idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "adcef74c-84e4-4244-b270-f7005888a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>p_stem</th>\n",
       "      <th>pos_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24638</th>\n",
       "      <td>inesse</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iness</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34548</th>\n",
       "      <td>pean</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pean</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10119</th>\n",
       "      <td>confessions</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>confess</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18569</th>\n",
       "      <td>farewell</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>farewel</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14282</th>\n",
       "      <td>disjoined</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disjoin</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>caesarian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>caesarian</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26206</th>\n",
       "      <td>iuventutem</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iuventutem</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33815</th>\n",
       "      <td>owed</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>owe</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>beakful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>beak</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43750</th>\n",
       "      <td>solebat</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>solebat</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            term_str   n  num  stop      p_stem pos_max\n",
       "term_id                                                \n",
       "24638         inesse   6    0     0       iness      NN\n",
       "34548           pean   6    0     0        pean      JJ\n",
       "10119    confessions  20    0     0     confess     NNS\n",
       "18569       farewell  24    0     0     farewel      NN\n",
       "14282      disjoined   5    0     0     disjoin     VBN\n",
       "7313       caesarian   1    0     0   caesarian      JJ\n",
       "26206     iuventutem   1    0     0  iuventutem      NN\n",
       "33815           owed  22    0     0         owe     VBD\n",
       "5639         beakful   1    0     0        beak      NN\n",
       "43750        solebat   3    0     0     solebat      NN"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bd514def-1cd2-404c-90ae-11246a7c768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "\n",
    "LIB.to_csv('LIB.csv')\n",
    "VOCAB.to_csv('VOCAB.csv')\n",
    "TOKEN.to_csv('TOKEN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4e3b876b-cee5-4341-9f18-cd3fe8739d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC.to_csv('DOC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644123f-7ccf-48dc-86bb-f9a530f3cf28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
