{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9f054e-5ca2-440b-a0d0-dd16cd583f92",
   "metadata": {},
   "source": [
    "## Exploring Philosophical Texts Across Gender, Region, and Time with Text Analytics\n",
    "### Haley Egan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18b654-c19f-42b5-807a-3431ce39bcd1",
   "metadata": {},
   "source": [
    "#### Project Overview\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369595c6-41e1-448a-9691-937d2e0c9084",
   "metadata": {},
   "source": [
    "The goal of this project is to explore the cultural patterns in philosophical texts. Main topics and cultural themes are analyzed across the texts as a whole. Topics and themes are also examined between groups, such as between male and female philosochical writers, between regions/nations, and across time. Text Analytics is a powerful tool to help us understand and extract cultural patterns from large quantities of texts.  \n",
    "\n",
    "Key Questions: \n",
    "- Do male and female philosophers explore different topics, or share similarites? \n",
    "- Are different topics discussed in different regions of the world? \n",
    "- Are different topics discussed in different time periods? \n",
    "- Can the key concepts of philosophical texts be extracted from each text, in an interpretable way? \n",
    "- What are the most important issues that philosophers are concerned with? Do these change over time, and do they differ based on gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f5fbc2-114c-4d6f-ac57-b04b4fc2e037",
   "metadata": {},
   "source": [
    "#### Project Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccc1df-dfdc-42ca-85dc-a99c8c0a642b",
   "metadata": {},
   "source": [
    "For this project, 21 philosophical texts were collected. Ten texts are by male Western philosophers, and span from 4th century BC to the 19th century AD. Four philosophical texts are by men from other parts of the world, including Asia and South America. Seven texts were collected by female Western philosophers, most of which are from the 20th century. These texts were collected from Project Gutenberg, and other online document archives. The texts are all in Plain-Text format, for easier use in data cleaning, parsing, and manipulation. Due to the necessity of the plain-text format, the available texts were limited, especially for the female philosophers. Most (known) published female philosophers are from the modern era, with limited free access to their works in plain-text form. This is the same for modern male philosophers. The distribution of texts is not even across time/gender, which must be taken into account when analysing the texts. There are many philosophical texts in the world, and this sample barely scratches the surface. Further exploration with more texts would provide greater understandings, and should be considered for future studies. However, there should still be enough textual data in order to address many cultural questions when looking at philosophical texts.\n",
    "\n",
    "- 10 Western Philosophical Texts by Male Authors: \n",
    "    - Aristotle: Nicomachean Ethics (4th century BC)\n",
    "    - Plato: The Republic (4th century BC)\n",
    "    - Cicero: On Moral Duties / De Officiis (44 BC)\n",
    "    - David Hume: An Enquiry Concerning Human Understanding (1748)\n",
    "    - Immanuel Kant: Fundamental Principles of the Metaphysic of Morals (1785)\n",
    "    - Karl Marx: The Communist Manifesto (1848)\n",
    "    - John Stuart Mill: Utilitarianism (1861) \n",
    "    - Friedrich Nietzsche: Beyond Good and Evil (1886)\n",
    "    - Søren Kierkegaard: Selections from the Writings of Kierkegaard (1923)\n",
    "    - Michel Foucault: The Order of Things (1966)\n",
    "- 4 Non-Western Philosophical Texts by Male Authors: \n",
    "    - Laozi (Lao Tzu): Tao Te Ching (400 BC) \n",
    "    - Paulo Freire: Pedagogy of the Oppressed (1968) \n",
    "    - **Sun Tzu: The Art of War (5th century BC)**\n",
    "    - Herman Hesse: Siddartha (1922) \n",
    "- 7 Western Phiosophical Texts by Female Authors:\n",
    "    - Mary Wollstonecraft: A Vindication of the Rights of Men (1790)\n",
    "    - Mary Wollstonecraft: A Vindication of the Rights of Woman (1792)\n",
    "    - Harriet Taylor Mill: The Enfranchisement of Women (1852)\n",
    "    - Simone de Beauvoir: The Second Sex (1952)\n",
    "    - Hannah Arendt: The Origins of Totalitarianism (1951)\n",
    "    - bell hooks: Ain’t I a Woman: Black Women and Feminism (1981)\n",
    "    - bell hooks: Feminist Class Struggle (2002) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfaeef-6f60-48c5-a3aa-4597d8d6892a",
   "metadata": {},
   "source": [
    "#### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb9b368-f976-4f5c-8032-89bda569d88e",
   "metadata": {},
   "source": [
    "Several Text Analytics tools are used for this project.\n",
    "- Bag-of-words:\n",
    "- TF-IDF:\n",
    "- Principle Component Analysis (PCA): \n",
    "- Latent Diriclet Analysis (LDA):\n",
    "- Topic Modeling:\n",
    "- Word Embeddings: word2vec\n",
    "- Visualizations:\n",
    "    - Cluster Diagrams:\n",
    "    - t-SNE:\n",
    "    - Dispersion Plots:\n",
    "    - Correlation heatmaps:\n",
    "    \n",
    "**Step 1**: Clean texts - import texts, remove beginning and end of texts that are not part of the main corpus. \n",
    "\n",
    "**Step 2**: Combine texts into one dataframe. From combined dataframe, create library table (LIB), document table (DOC), token table (TOKEN), and vocabulary table (VOCAB), all exported as csv files. \n",
    "- LIB: basic metadata about each book\n",
    "- DOC: preserved paragraphs of each book and appropriate OHCO index\n",
    "- TOKEN: OHCO index and parts-of-speech tags derived from NLTK\n",
    "- VOCAB: NLTK to extract stopwords, porter stems, 'pos_max' that contains most frequent parts-of-speech tags from TOKEN table\n",
    "** These documents do not follow a traditional chapter structure\n",
    "\n",
    "**Step 3**: \n",
    "- Build TF-IDF Matrix. \n",
    "- Get TF-IDF for texts. \n",
    "- Create Bag-of-Words.\n",
    "\n",
    "**Step 4**: PCA\n",
    "- Reduce number of features by removing proper nouns and insignificant words\n",
    "- Vectorize TF-IDF and extract term covariance matrix\n",
    "- Apply eigendecomposition to COV table\n",
    "- Look at top components from each text\n",
    "- Look at top componenets by author gender\n",
    "- Plots: covariance matrix, eigen tables, Document Component Matrix (DCM), scatter plots\n",
    "\n",
    "**Step 5**: Distance Metrics\n",
    "- Plots: cluster diagrams for texts by year\n",
    "\n",
    "**Step 6**: Topic Modeling\n",
    "- Top overall topics & topics by weight\n",
    "- Topics by gender\n",
    "- Topics by era\n",
    "- Topics by region\n",
    "- Plots: cluster diagrams, gradient graphs, horizontal bar charts, topic tables\n",
    "\n",
    "**Step 7**: Word Embeddings\n",
    "- Specific authors\n",
    "- word2vec\n",
    "- t-SNE Plots by author\n",
    "- Semantic Algebra\n",
    "\n",
    "**Step 8**:Sentiment Analysis\n",
    "- NCR lexicons (multiple languages?)\n",
    "- 8 emotions\n",
    "- top emotions per text\n",
    "- top emotions per group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a85e2e-5558-40dc-baa3-f1decac15fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ea1048-365d-42f2-8f1b-7d8305b2b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f80175-e4bc-4bc5-8134-c7530a57a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\haley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\haley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\haley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\haley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLTK downloads\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acba68ed-fe35-4b88-9567-1bcac399e85f",
   "metadata": {},
   "source": [
    "#### OHCO Model & Structure Decisions\n",
    "\n",
    "An OHCO Model stands for Ordered Hierarchy of Content Objects. Breaking text elements down to the OHCO hierarchical levels allows us to create a database of text elements for data exploration. \n",
    "\n",
    "For this project, the OHCO is set to text_id, which is the unique ID given to each text to help distinguish it quickly from other texts, para_num, which is the unique count index given to each paragraph per text, sent_num, the unique count index given to each sentence per text, and token_num, the unique count index given for each individual token, or word. Many OHCO models include chapter numbers, so that the texts can be examined on a chapter level. This is often less computationally costly than examining a text at the paragraph or sentence level, especially for very long texts. However, for this project chapters are not included, because most of the philosophical texts do not follow a chapter structure. For example, the two texts by Wollstonecraft follow a letter format, and the texts by hooks are in essay format. Due to the inconsistencies in document structure, the documents are broken down to the paragraph, sentence, and token level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a126be0e-16e7-401b-a196-2c971c6cd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set OHCO\n",
    "OHCO = ['text_id', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b55e52-ba60-41bd-9556-aa642a4083dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory for philosophy texts\n",
    "philostext_dir = 'philostexts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f63854-c86c-4f88-92b6-f1b693bcca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify start and end of texts, make uniform chapters\n",
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "chap_pats = {\n",
    "    1: {\n",
    "        'start_line': 17,\n",
    "        'end_line': 7723},\n",
    "    2: {\n",
    "        'start_line': 14,\n",
    "        'end_line': 9370},\n",
    "    3: {\n",
    "        'start_line': 7,\n",
    "        'end_line': 180},\n",
    "     4: {\n",
    "        'start_line': 90,\n",
    "        'end_line': 12102}, \n",
    "      5: {\n",
    "        'start_line': 1081,\n",
    "        'end_line': 19707},\n",
    "      6: {\n",
    "        'start_line': 396,\n",
    "        'end_line': 4716},\n",
    "      7: {\n",
    "        'start_line': 502,\n",
    "        'end_line': 30458},\n",
    "      8: {\n",
    "        'start_line': 155,\n",
    "        'end_line': 1371},\n",
    "      9: {\n",
    "        'start_line': 72,\n",
    "        'end_line': 3992},\n",
    "      10: {\n",
    "        'start_line': 89,\n",
    "        'end_line': 5281},\n",
    "    11: {\n",
    "        'start_line': 62,\n",
    "        'end_line': 3113},\n",
    "    12: {\n",
    "        'start_line': 107,\n",
    "        'end_line': 8653},\n",
    "    13: {\n",
    "        'start_line': 80,\n",
    "        'end_line': 1433},\n",
    "    14: {\n",
    "        'start_line': 75,\n",
    "        'end_line': 2319},\n",
    "    15: {\n",
    "        'start_line': 618,\n",
    "        'end_line': 9483},\n",
    "    16: {\n",
    "        'start_line': 151,\n",
    "        'end_line': 6007},\n",
    "    17: {\n",
    "        'start_line': 61,\n",
    "        'end_line': 24563},\n",
    "    18: {\n",
    "        'start_line': 902,\n",
    "        'end_line': 39254},\n",
    "    19: {\n",
    "        'start_line': 12,\n",
    "        'end_line': 2437},\n",
    "    #20: {\n",
    "     #   'start_line': 268,\n",
    "     #   'end_line': 6783,\n",
    "    # },\n",
    "    21: {\n",
    "        'start_line': 135,\n",
    "        'end_line': 2739}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927ecd58-df09-46c5-be29-6d04291f2423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['philostexts\\\\Aristotle_NicomachaenEthics-1.txt',\n",
       " 'philostexts\\\\Cicero_OnDuties-4.txt',\n",
       " 'philostexts\\\\Foucault_TheOrderofThings-5.txt',\n",
       " 'philostexts\\\\Freire_PedagogyOfTheOppressed-6.txt',\n",
       " 'philostexts\\\\HannahArendt_TheOriginsofTotalitarianism-7.txt',\n",
       " 'philostexts\\\\HarrietTaylorMill_EnfranchisementofWomen-8.txt',\n",
       " 'philostexts\\\\Hesse_Siddhartha-9.txt',\n",
       " 'philostexts\\\\Hume_AnEnquiryConcerningHumanUnderstanding-10.txt',\n",
       " 'philostexts\\\\Kant_MetaphysicsOfMorals-11.txt',\n",
       " 'philostexts\\\\Kierkegaard_CollectionOfWritings-12.txt',\n",
       " 'philostexts\\\\Laozi_TaoTeChing-21.txt',\n",
       " 'philostexts\\\\Marx_CommunistManifesto-13.txt',\n",
       " 'philostexts\\\\MaryWollstonecraft_AVindicationOfTheRightsofMen-14.txt',\n",
       " 'philostexts\\\\MaryWollstonecraft_AVindicationOfTheRightsofWoman-15.txt',\n",
       " 'philostexts\\\\Nietzsche_BeyondGoodandEvil-16.txt',\n",
       " 'philostexts\\\\Plato_TheRepublic-17.txt',\n",
       " 'philostexts\\\\Simonedebeauvoir_TheSecondSex-18.txt',\n",
       " 'philostexts\\\\StuartMill_Utilitarianism-19.txt',\n",
       " 'philostexts\\\\bellhooks_AintIAWoman-2.txt',\n",
       " 'philostexts\\\\bellhooks_FeministClassStruggle-3.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a list of all text files\n",
    "text_list = [text for text in sorted(glob(philostext_dir+'/*.txt'))]\n",
    "text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5d8af-c69b-49f1-99b8-78ebb91d202e",
   "metadata": {},
   "source": [
    "### Clean Texts and Build Library and Document Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f16cf3f-d11c-4463-9991-cebd2e5ec8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean texts, split into paragraphs, and build dataframes\n",
    "def clean_texts(text_list, chap_pats, OHCO=OHCO):\n",
    "    lib = []\n",
    "    doc = []\n",
    "    for text in text_list:\n",
    "        # Get ID from filename\n",
    "        text_id = int(text.split('-')[-1].split('.')[0])\n",
    "        #print(text_id)\n",
    "\n",
    "        #get text title \n",
    "        text_title = text.split('_')[-1].split('-')[0]\n",
    "        #print(text_title)\n",
    "\n",
    "        #get text author\n",
    "        text_author = text.split('\\\\')[-1].split('_')[0]\n",
    "        #print(text_author)    \n",
    "\n",
    "        #read files as lines\n",
    "        lines = open(text, 'r', encoding='utf-8-sig').readlines()\n",
    "        \n",
    "        #create dataframe to store text details\n",
    "        df = pd.DataFrame(lines, columns=['line_str']) #add lines to df\n",
    "        df.index.name = 'line_num' #set line_num as index for each line_str\n",
    "        df.line_str = df.line_str.str.strip() #strip white space from lines\n",
    "        #df['text_id'] = text_id #add text_id column to df\n",
    "        \n",
    "        #remove inconsistent chapter headings\n",
    "        df.line_str = df.line_str.replace(r'CHAPTER', '').str.strip()\n",
    "        df.line_str = df.line_str.replace(r'Chapter', '').str.strip()\n",
    "        \n",
    "        #remove page numbers\n",
    "        df.line_str = df.line_str.str.replace(r'[0-9]+', '')\n",
    "        \n",
    "        # fix characters to improve tokenization\n",
    "        df.line_str = df.line_str.str.replace('—', ' — ')\n",
    "        df.line_str = df.line_str.str.replace('-', ' - ')\n",
    "        \n",
    "        #remove unimportant stuff at begininng and end of texts\n",
    "        a = chap_pats[text_id]['start_line'] - 1\n",
    "        b = chap_pats[text_id]['end_line'] + 1\n",
    "        df = df.iloc[a:b]    \n",
    "\n",
    "        #split into paragraphs\n",
    "        df = df['line_str'].str.split(r'\\n\\n+', expand=True).stack().to_frame().rename(columns={0:'para_str'})\n",
    "        df.index.names = OHCO[1:3]\n",
    "        df['para_str'] = df['para_str'].str.replace(r'\\n', ' ').str.strip()\n",
    "        df = df[~df['para_str'].str.match(r'^\\s*$')] # Remove empty paragraphs    \n",
    "\n",
    "        # Set index\n",
    "        df['text_id'] = text_id\n",
    "        df = df.reset_index().set_index(OHCO[:2])  \n",
    "        df = df.drop(['sent_num'], axis=1) #drop sent_num - not needed at this point  \n",
    "\n",
    "        #append extracted into to lists\n",
    "        lib.append((text_id, text_title, text_author, text))\n",
    "        doc.append(df)\n",
    "    \n",
    "    docs = pd.concat(doc) #put all doc into into dataframe format \n",
    "    #create new df with title, author, file, and text id index\n",
    "    library = pd.DataFrame(lib, columns=['text_id', 'title', 'author', 'file']).set_index('text_id')\n",
    "    return docs, library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54fedda-6ae1-4342-acd1-12d630f6e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to make LIB and DOC tables\n",
    "DOC, LIB = clean_texts(text_list, chap_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e637cd53-b902-4afa-bf19-a105e86b066a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TheRepublic</td>\n",
       "      <td>Plato</td>\n",
       "      <td>philostexts\\Plato_TheRepublic-17.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NicomachaenEthics</td>\n",
       "      <td>Aristotle</td>\n",
       "      <td>philostexts\\Aristotle_NicomachaenEthics-1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Utilitarianism</td>\n",
       "      <td>StuartMill</td>\n",
       "      <td>philostexts\\StuartMill_Utilitarianism-19.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BeyondGoodandEvil</td>\n",
       "      <td>Nietzsche</td>\n",
       "      <td>philostexts\\Nietzsche_BeyondGoodandEvil-16.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PedagogyOfTheOppressed</td>\n",
       "      <td>Freire</td>\n",
       "      <td>philostexts\\Freire_PedagogyOfTheOppressed-6.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OnDuties</td>\n",
       "      <td>Cicero</td>\n",
       "      <td>philostexts\\Cicero_OnDuties-4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CollectionOfWritings</td>\n",
       "      <td>Kierkegaard</td>\n",
       "      <td>philostexts\\Kierkegaard_CollectionOfWritings-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FeministClassStruggle</td>\n",
       "      <td>bellhooks</td>\n",
       "      <td>philostexts\\bellhooks_FeministClassStruggle-3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EnfranchisementofWomen</td>\n",
       "      <td>HarrietTaylorMill</td>\n",
       "      <td>philostexts\\HarrietTaylorMill_Enfranchisemento...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TheOrderofThings</td>\n",
       "      <td>Foucault</td>\n",
       "      <td>philostexts\\Foucault_TheOrderofThings-5.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title             author  \\\n",
       "text_id                                              \n",
       "17                  TheRepublic              Plato   \n",
       "1             NicomachaenEthics          Aristotle   \n",
       "19               Utilitarianism         StuartMill   \n",
       "16            BeyondGoodandEvil          Nietzsche   \n",
       "6        PedagogyOfTheOppressed             Freire   \n",
       "4                      OnDuties             Cicero   \n",
       "12         CollectionOfWritings        Kierkegaard   \n",
       "3         FeministClassStruggle          bellhooks   \n",
       "8        EnfranchisementofWomen  HarrietTaylorMill   \n",
       "5              TheOrderofThings           Foucault   \n",
       "\n",
       "                                                      file  \n",
       "text_id                                                     \n",
       "17                    philostexts\\Plato_TheRepublic-17.txt  \n",
       "1            philostexts\\Aristotle_NicomachaenEthics-1.txt  \n",
       "19            philostexts\\StuartMill_Utilitarianism-19.txt  \n",
       "16          philostexts\\Nietzsche_BeyondGoodandEvil-16.txt  \n",
       "6          philostexts\\Freire_PedagogyOfTheOppressed-6.txt  \n",
       "4                        philostexts\\Cicero_OnDuties-4.txt  \n",
       "12       philostexts\\Kierkegaard_CollectionOfWritings-1...  \n",
       "3        philostexts\\bellhooks_FeministClassStruggle-3.txt  \n",
       "8        philostexts\\HarrietTaylorMill_Enfranchisemento...  \n",
       "5              philostexts\\Foucault_TheOrderofThings-5.txt  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "967a17cc-d7d4-486b-867d-0817770dadcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>para_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>8130</th>\n",
       "      <td>senses will ever be at work to harden their he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>3789</th>\n",
       "      <td>Bopp, Ray and Cuvier, Petty and Ricardo, the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>11762</th>\n",
       "      <td>slain my son.’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>623</th>\n",
       "      <td>understand me, which I do not suppose many per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>13967</th>\n",
       "      <td>poet Tyutchev asserted at the same time that \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>6782</th>\n",
       "      <td>ipsi est, tum etiam sordidum ad famam, committ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>34531</th>\n",
       "      <td>Bashkirtseff was so intoxicated by her beauty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>1866</th>\n",
       "      <td>saw them complaining about pain at which a Sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>2990</th>\n",
       "      <td>heaven of OUR life. There are few pains so gri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>3827</th>\n",
       "      <td>She, however, seemed only to be glad that it t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           para_str\n",
       "text_id para_num                                                   \n",
       "15      8130      senses will ever be at work to harden their he...\n",
       "5       3789      Bopp, Ray and Cuvier, Petty and Ricardo, the f...\n",
       "17      11762                                        slain my son.’\n",
       "15      623       understand me, which I do not suppose many per...\n",
       "7       13967     poet Tyutchev asserted at the same time that \"...\n",
       "4       6782      ipsi est, tum etiam sordidum ad famam, committ...\n",
       "18      34531     Bashkirtseff was so intoxicated by her beauty ...\n",
       "9       1866      saw them complaining about pain at which a Sam...\n",
       "16      2990      heaven of OUR life. There are few pains so gri...\n",
       "12      3827      She, however, seemed only to be glad that it t..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a394ef1-75d7-411b-973a-28d198774512",
   "metadata": {},
   "source": [
    "### Create TOKEN table to extract NLTK Part-of-Speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dce7354-4d36-492e-b27d-e86bf9991f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "    # Paragraphs to Sentences\n",
    "    df = doc_df.para_str\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    # Sentences to Tokens\n",
    "    # Local function to pick tokenizer\n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x)))\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fed85c4-7693-4f7d-a4e3-7e6548dfb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = tokenize(DOC, ws=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec0dead-e223-46f6-91d9-4a56263885d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">16</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Every, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>Every</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(art, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(and, CC)</td>\n",
       "      <td>CC</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(every, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>every</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(inquiry,, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>inquiry,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          pos_tuple pos token_str\n",
       "text_id para_num sent_num token_num                              \n",
       "1       16       0        0             (Every, DT)  DT     Every\n",
       "                          1               (art, NN)  NN       art\n",
       "                          2               (and, CC)  CC       and\n",
       "                          3             (every, DT)  DT     every\n",
       "                          4          (inquiry,, NN)  NN  inquiry,"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e11c6-eb17-44bd-a27a-9aac334020dc",
   "metadata": {},
   "source": [
    "### Create VOCAB Table with NLTK Stopwords, Porter Stems, Most Frequent Parts-of-Speech Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "315b22ee-bf66-42ee-8628-3843961782ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>32337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>34591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aarhus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50195</th>\n",
       "      <td>ἅπαν</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50196</th>\n",
       "      <td>ἐξοίχεται</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50197</th>\n",
       "      <td>ὁρμαί</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50198</th>\n",
       "      <td>ὁρμάς</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50199</th>\n",
       "      <td>ὁρμή</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          term_str      n  num\n",
       "term_id                       \n",
       "0                   32337    0\n",
       "1                a  34591    0\n",
       "2               aa      4    0\n",
       "3           aarhus      1    0\n",
       "4               ab    105    0\n",
       "...            ...    ...  ...\n",
       "50195         ἅπαν      1    0\n",
       "50196    ἐξοίχεται      1    0\n",
       "50197        ὁρμαί      1    0\n",
       "50198        ὁρμάς      1    0\n",
       "50199         ὁρμή      2    0\n",
       "\n",
       "[50200 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract a vocabulary from the TOKEN table\n",
    "TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '') #lowercase all, remove anything that's not a letter\n",
    "\n",
    "VOCAB = TOKEN.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'\n",
    "\n",
    "VOCAB['num'] = VOCAB.term_str.str.match(\"\\d+\").astype('int')\n",
    "\n",
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f0bc7d6-ddfa-4d49-8f5e-c5bf5293c849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>such</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>should've</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she's</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wouldn't</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aren</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>been</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haven't</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dummy\n",
       "term_str        \n",
       "such           1\n",
       "should've      1\n",
       "she's          1\n",
       "wouldn't       1\n",
       "who            1\n",
       "be             1\n",
       "him            1\n",
       "aren           1\n",
       "been           1\n",
       "haven't        1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add stopwords\n",
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1\n",
    "sw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dfacee6-608f-43e1-9f09-6644ecca7776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29147</th>\n",
       "      <td>more</td>\n",
       "      <td>5192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49697</th>\n",
       "      <td>won</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20555</th>\n",
       "      <td>he</td>\n",
       "      <td>12294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24409</th>\n",
       "      <td>itself</td>\n",
       "      <td>1750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20522</th>\n",
       "      <td>haven</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>about</td>\n",
       "      <td>1825</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29566</th>\n",
       "      <td>my</td>\n",
       "      <td>1951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50025</th>\n",
       "      <td>your</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>against</td>\n",
       "      <td>1352</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49378</th>\n",
       "      <td>what</td>\n",
       "      <td>4727</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str      n  num  stop\n",
       "term_id                           \n",
       "29147       more   5192    0     1\n",
       "49697        won     82    0     1\n",
       "20555         he  12294    0     1\n",
       "24409     itself   1750    0     1\n",
       "20522      haven      8    0     1\n",
       "127        about   1825    0     1\n",
       "29566         my   1951    0     1\n",
       "50025       your    917    0     1\n",
       "1226     against   1352    0     1\n",
       "49378       what   4727    0     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB['stop'] = VOCAB.term_str.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')\n",
    "\n",
    "VOCAB[VOCAB.stop == 1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee8734b-bc17-4524-9f93-42b58f9d749d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>p_stem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6286</th>\n",
       "      <td>castigatione</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>castigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47196</th>\n",
       "      <td>unleashed</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unleash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28368</th>\n",
       "      <td>mice</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41738</th>\n",
       "      <td>snivel</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>snivel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49439</th>\n",
       "      <td>whispering</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>whisper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31129</th>\n",
       "      <td>offhand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>offhand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45024</th>\n",
       "      <td>theres</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>applications</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>applic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26118</th>\n",
       "      <td>lhistoire</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lhistoir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43842</th>\n",
       "      <td>suppliant</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>suppliant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term_str   n  num  stop       p_stem\n",
       "term_id                                          \n",
       "6286     castigatione   1    0     0  castigation\n",
       "47196       unleashed   3    0     0      unleash\n",
       "28368            mice   1    0     0         mice\n",
       "41738          snivel   1    0     0       snivel\n",
       "49439      whispering   8    0     0      whisper\n",
       "31129         offhand   1    0     0      offhand\n",
       "45024          theres   7    0     0        there\n",
       "2550     applications  13    0     0       applic\n",
       "26118       lhistoire   1    0     0     lhistoir\n",
       "43842       suppliant   1    0     0    suppliant"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add stems\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "VOCAB['p_stem'] = VOCAB.term_str.apply(stemmer.stem)\n",
    "\n",
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97028255-a343-421b-b9bf-132e032407d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>1864</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <td>(for, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">17</th>\n",
       "      <th>2857</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <td>(from, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20171</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>(be, VB)</td>\n",
       "      <td>VB</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>113</th>\n",
       "      <th>0</th>\n",
       "      <th>7</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>14242</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <td>(therefore, VB)</td>\n",
       "      <td>VB</td>\n",
       "      <td>therefore</td>\n",
       "      <td>therefore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>2142</th>\n",
       "      <th>0</th>\n",
       "      <th>6</th>\n",
       "      <td>(of, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>10048</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <td>(was, VBD)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>6441</th>\n",
       "      <th>0</th>\n",
       "      <th>10</th>\n",
       "      <td>(its, PRP$)</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>its</td>\n",
       "      <td>its</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>1036</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>(When, WRB)</td>\n",
       "      <td>WRB</td>\n",
       "      <td>When</td>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>16191</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <td>(experience, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>experience</td>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pos_tuple   pos   token_str  \\\n",
       "text_id para_num sent_num token_num                                       \n",
       "9       1864     0        6                 (for, IN)    IN         for   \n",
       "17      2857     0        6                (from, IN)    IN        from   \n",
       "        20171    0        1                  (be, VB)    VB          be   \n",
       "19      113      0        7                 (the, DT)    DT         the   \n",
       "5       14242    1        4           (therefore, VB)    VB   therefore   \n",
       "9       2142     0        6                  (of, IN)    IN          of   \n",
       "18      10048    0        3                (was, VBD)   VBD         was   \n",
       "15      6441     0        10              (its, PRP$)  PRP$         its   \n",
       "8       1036     1        0               (When, WRB)   WRB        When   \n",
       "18      16191    0        4          (experience, NN)    NN  experience   \n",
       "\n",
       "                                       term_str  \n",
       "text_id para_num sent_num token_num              \n",
       "9       1864     0        6                 for  \n",
       "17      2857     0        6                from  \n",
       "        20171    0        1                  be  \n",
       "19      113      0        7                 the  \n",
       "5       14242    1        4           therefore  \n",
       "9       2142     0        6                  of  \n",
       "18      10048    0        3                 was  \n",
       "15      6441     0        10                its  \n",
       "8       1036     1        0                when  \n",
       "18      16191    0        4          experience  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d86b25df-c0cb-4d1b-b649-bfbe7db6484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 'term_id' column to table to make it easier of merging tables \n",
    "TOKEN['term_id'] = TOKEN.term_str.map(VOCAB.reset_index().set_index('term_str').term_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a2dddee-ec0e-4eb1-a1d0-cbc6a1f4563b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>term_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">16</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Every, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>Every</td>\n",
       "      <td>every</td>\n",
       "      <td>15890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(art, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>art</td>\n",
       "      <td>art</td>\n",
       "      <td>2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(and, CC)</td>\n",
       "      <td>CC</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(every, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>every</td>\n",
       "      <td>every</td>\n",
       "      <td>15890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(inquiry,, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>inquiry,</td>\n",
       "      <td>inquiry</td>\n",
       "      <td>23364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          pos_tuple pos token_str term_str  \\\n",
       "text_id para_num sent_num token_num                                          \n",
       "1       16       0        0             (Every, DT)  DT     Every    every   \n",
       "                          1               (art, NN)  NN       art      art   \n",
       "                          2               (and, CC)  CC       and      and   \n",
       "                          3             (every, DT)  DT     every    every   \n",
       "                          4          (inquiry,, NN)  NN  inquiry,  inquiry   \n",
       "\n",
       "                                     term_id  \n",
       "text_id para_num sent_num token_num           \n",
       "1       16       0        0            15890  \n",
       "                          1             2942  \n",
       "                          2             1976  \n",
       "                          3            15890  \n",
       "                          4            23364  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f06f171f-a734-4d51-97fc-df66eaa12da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, add a feature named \"pos_max\" to the VOCAB table that contains the most frequently \n",
    "#associated part-of-speech tag, as found in the TOKEN table, with each term.\n",
    "VOCAB['pos_max'] = TOKEN.groupby(['term_id', 'pos']).count().iloc[:,0].unstack().idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adcef74c-84e4-4244-b270-f7005888a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>p_stem</th>\n",
       "      <th>pos_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14176</th>\n",
       "      <td>effectuate</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>effectu</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24174</th>\n",
       "      <td>iracundiam</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>iracundiam</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>amicably</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>amic</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>accomplice</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accomplic</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32976</th>\n",
       "      <td>peperit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>peperit</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37322</th>\n",
       "      <td>reconquest</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reconquest</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8590</th>\n",
       "      <td>coneemed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>coneem</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42793</th>\n",
       "      <td>stautes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>staut</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36799</th>\n",
       "      <td>rain</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rain</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26828</th>\n",
       "      <td>lubricus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lubricu</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term_str   n  num  stop      p_stem pos_max\n",
       "term_id                                               \n",
       "14176    effectuate   3    0     0     effectu      VB\n",
       "24174    iracundiam   2    0     0  iracundiam      NN\n",
       "1798       amicably   2    0     0        amic      NN\n",
       "350      accomplice   6    0     0   accomplic      NN\n",
       "32976       peperit   1    0     0     peperit      NN\n",
       "37322    reconquest   1    0     0  reconquest      NN\n",
       "8590       coneemed   1    0     0      coneem     VBN\n",
       "42793       stautes   1    0     0       staut     NNP\n",
       "36799          rain  26    0     0        rain      NN\n",
       "26828      lubricus   1    0     0     lubricu      NN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd514def-1cd2-404c-90ae-11246a7c768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "DOC.to_csv('DOC.csv')\n",
    "LIB.to_csv('LIB.csv')\n",
    "VOCAB.to_csv('VOCAB.csv')\n",
    "TOKEN.to_csv('TOKEN.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
